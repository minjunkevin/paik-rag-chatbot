import os
import streamlit as st

# âœ… ë°°í¬/ë¡œì»¬ ê³µí†µ: secrets ìš°ì„ , ì—†ìœ¼ë©´ OS env ì‚¬ìš©
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
if "DEEPSEEK_API_KEY" in st.secrets:
    os.environ["DEEPSEEK_API_KEY"] = st.secrets["DEEPSEEK_API_KEY"]
os.environ["DEEPSEEK_BASE_URL"] = st.secrets.get(
    "DEEPSEEK_BASE_URL",
    os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
)

import rag_core
from rag_core import Chunk
from rag_core import load_vectorstore, rag_qa
from rag_core import answer_stream


# =========================
# Streamlit page config
# =========================
st.set_page_config(
    page_title="ë°±ë‚¨ì¤€ ì±—ë´‡",
    page_icon="ğŸ§ ",
    layout="centered",
)

# =========================
# Minimal ChatGPT-like CSS
# =========================
st.markdown("""
<style>
/* Chat container width */
.block-container { max-width: 860px; }

/* Make chat a bit tighter */
.stChatMessage { padding: 8px 0; }

/* Code blocks */
pre { border-radius: 12px !important; }

/* Sidebar titles */
.sidebar-title { font-weight: 700; font-size: 14px; margin-bottom: 8px; }

/* Smaller captions */
.small-caption { font-size: 12px; opacity: 0.8; }
</style>
""", unsafe_allow_html=True)


# =========================
# Load VectorStore once
# =========================
@st.cache_resource(show_spinner=True)
def get_vs(vs_dir: str):
    return load_vectorstore(vs_dir)


# =========================
# Catalog / sources
# =========================
# âš ï¸ ì—¬ê¸°ëŠ” ë„¤ chunks metadataì— ë“¤ì–´ìˆëŠ” source ì´ë¦„ê³¼ ë§ì•„ì•¼ í•¨.
# ë³´í†µ ë„ˆê°€ ìƒì„±í•  ë•Œ ë„£ì—ˆë˜ SOURCES["source"] ê°’ë“¤.
# =========================
# Catalog / sources + (Aì•ˆ) íŒŒì¼ë³„ í•œì¤„ ì„¤ëª…
# =========================
ALL_SOURCES = [
    "ë°±ë‚¨ì¤€ ì—°ëŒ€ê¸°_ë°±ë‚¨ì¤€ë¬¸í™”ì˜ˆìˆ ì¬ë‹¨.xlsx",
    "ë°±ë‚¨ì¤€ í¼í¬ë¨¼ìŠ¤ ëª©ë¡.pdf",
    "ë°±ë‚¨ì¤€ ì°¸ì—¬ì „ì‹œëª©ë¡_ê·¸ë£¹ì „.pdf",
    "ë°±ë‚¨ì¤€ ì°¸ì—¬ì „ì‹œëª©ë¡_ê°œì¸ì „.pdf",
    "ë°±ë‚¨ì¤€ ì°¸ê³ ë¬¸í—Œëª©ë¡_ì¼ë°˜.pdf",
    "ë°±ë‚¨ì¤€ ì°¸ê³ ë¬¸í—Œëª©ë¡_ì¸í„°ë·°.pdf",
    "ë°±ë‚¨ì¤€ ì°¸ê³ ë¬¸í—Œëª©ë¡_ê¸°ì‚¬.pdf",
    "ë°±ë‚¨ì¤€ ì‘í’ˆëª©ë¡_ì˜í™”.pdf",
    "ë°±ë‚¨ì¤€ ì‘í’ˆëª©ë¡_ë‹¨ì±„ë„ë¹„ë””ì˜¤.pdf",
    "ë°±ë‚¨ì¤€ ì‘í’ˆëª©ë¡_ë‹¤íë©˜í„°ë¦¬ ë¹„ë””ì˜¤.pdf",
    "The_Worlds_of_Nam_June_Paik_2000.pdf",
    "ë°±ë‚¨ì¤€ í•´ì™¸ê¸°ì‚¬_NER,POS.xlsx",
    "ë°±ë‚¨ì¤€-ì•„ì¹´ì´ë¸Œì „-ì „ì‹œ-ì„œë¬¸.pdf",
    "ê¹€ê¸ˆë¯¸_ë°±ë‚¨ì¤€ê¸°ë…ê´€-ê°•ì—°-ì›ê³ .pdf",
    "8.The-Mysteries-of-Encounters-between-Nam_June_Paik-John_Cage-and-Joseph_Beuys.pdf",
    "[ë°±ë‚¨ì¤€ ì‘í’ˆ 13ì„ ] ì†Œì¥ì²˜ ì •ë¦¬ (2).xlsx",
    "ë°±ë‚¨ì¤€ í•´ì™¸ì†Œì¥ í˜„í™© ì—…ë°ì´íŠ¸_2026ver.xlsx",
    "ë°±ë‚¨ì¤€ ë§ì—ì„œ í¬ë¦¬ìŠ¤í†  (OCR PDF)",

]

# âœ… (Aì•ˆ í•µì‹¬) íŒŒì¼ë³„ "ë¬´ìŠ¨ ë‚´ìš©ì¸ì§€" í•œ ì¤„ ì„¤ëª…
# - ë¼ìš°í„°(DeepSeek)ê°€ íŒŒì¼ëª…ì„ ë³´ê³  ì¶”ì¸¡í•˜ëŠ” ëŒ€ì‹ , ì„¤ëª…ê¹Œì§€ ë³´ê³  ë” ì •í™•íˆ sourcesë¥¼ ê³ ë¦…ë‹ˆë‹¤.
SOURCE_DESCRIPTIONS = {
    "ë°±ë‚¨ì¤€ ì—°ëŒ€ê¸°_ë°±ë‚¨ì¤€ë¬¸í™”ì˜ˆìˆ ì¬ë‹¨.xlsx": "ë°±ë‚¨ì¤€ ìƒì• /í™œë™ ì—°í‘œ(ì—°ë„ë³„ ì£¼ìš” ì‚¬ê±´, ì „ì‹œ/í™œë™ ë§¥ë½)",
    "ë°±ë‚¨ì¤€ í¼í¬ë¨¼ìŠ¤ ëª©ë¡.pdf": "í¼í¬ë¨¼ìŠ¤/í–‰ìœ„ ê´€ë ¨ ëª©ë¡(ì‘í’ˆ/í–‰ì‚¬ëª…, ì‹œê¸°, ì¥ì†Œ ë“±)",
    "ë°±ë‚¨ì¤€ ì°¸ì—¬ì „ì‹œëª©ë¡_ê·¸ë£¹ì „.pdf": "ê·¸ë£¹ì „ ì°¸ì—¬ ì „ì‹œ ëª©ë¡(ì „ì‹œëª…, ê¸°ê°„, ì¥ì†Œ ë“±)",
    "ë°±ë‚¨ì¤€ ì°¸ì—¬ì „ì‹œëª©ë¡_ê°œì¸ì „.pdf": "ê°œì¸ì „ ì „ì‹œ ëª©ë¡(ì „ì‹œëª…, ê¸°ê°„, ì¥ì†Œ ë“±)",
    "ë°±ë‚¨ì¤€ ì°¸ê³ ë¬¸í—Œëª©ë¡_ì¼ë°˜.pdf": "ì°¸ê³ ë¬¸í—Œ ëª©ë¡(ì¼ë°˜ ë„ì„œ/ìë£Œ ì„œì§€ì •ë³´)",
    "ë°±ë‚¨ì¤€ ì°¸ê³ ë¬¸í—Œëª©ë¡_ì¸í„°ë·°.pdf": "ì°¸ê³ ë¬¸í—Œ ì¤‘ ì¸í„°ë·° ìë£Œ ëª©ë¡(ì¸í„°ë·°ì´/ë§¤ì²´/ì—°ë„ ë“±)",
    "ë°±ë‚¨ì¤€ ì°¸ê³ ë¬¸í—Œëª©ë¡_ê¸°ì‚¬.pdf": "ì°¸ê³ ë¬¸í—Œ ì¤‘ ê¸°ì‚¬/ë³´ë„ ìë£Œ ëª©ë¡(ì‹ ë¬¸/ì¡ì§€/ë‚ ì§œ ë“±)",
    "ë°±ë‚¨ì¤€ ì‘í’ˆëª©ë¡_ì˜í™”.pdf": "ì‘í’ˆ ëª©ë¡(ì˜í™” ê´€ë ¨) â€“ ì‘í’ˆëª…/ì œì‘ì—°ë„/í˜•ì‹ ë“±",
    "ë°±ë‚¨ì¤€ ì‘í’ˆëª©ë¡_ë‹¨ì±„ë„ë¹„ë””ì˜¤.pdf": "ì‘í’ˆ ëª©ë¡(ë‹¨ì±„ë„ ë¹„ë””ì˜¤) â€“ ì‘í’ˆëª…/ì—°ë„/í˜•ì‹ ë“±",
    "ë°±ë‚¨ì¤€ ì‘í’ˆëª©ë¡_ë‹¤íë©˜í„°ë¦¬ ë¹„ë””ì˜¤.pdf": "ì‘í’ˆ ëª©ë¡(ë‹¤íë©˜í„°ë¦¬ ë¹„ë””ì˜¤) â€“ ì‘í’ˆëª…/ì—°ë„ ë“±",
    "The_Worlds_of_Nam_June_Paik_2000.pdf": "ì „ì‹œ/ë„ë¡ ì„±ê²©ì˜ ìë£Œ(ì‘í’ˆ/ì—ì„¸ì´/ì „ì‹œ ë§¥ë½ í¬í•¨ ê°€ëŠ¥)",
    "ë°±ë‚¨ì¤€ í•´ì™¸ê¸°ì‚¬_NER,POS.xlsx": "í•´ì™¸ ê¸°ì‚¬ í…ìŠ¤íŠ¸/ë¶„ì„ ê²°ê³¼(ì¸ë¬¼/ì§€ëª…/í‚¤ì›Œë“œ, ë¬¸ì¥ ë‹¨ìœ„ ì •ë³´ ê°€ëŠ¥)",
    "ë°±ë‚¨ì¤€-ì•„ì¹´ì´ë¸Œì „-ì „ì‹œ-ì„œë¬¸.pdf": "ì•„ì¹´ì´ë¸Œ ì „ì‹œ ì„œë¬¸/ê¸°íš ê¸€(ì „ì‹œ ì˜ë„/í•´ì„/ë§¥ë½)",
    "ê¹€ê¸ˆë¯¸_ë°±ë‚¨ì¤€ê¸°ë…ê´€-ê°•ì—°-ì›ê³ .pdf": "ê°•ì—° ì›ê³ (í•´ì„¤/ë¹„í‰/ë§¥ë½ ì„¤ëª… ì¤‘ì‹¬)",
    "8.The-Mysteries-of-Encounters-between-Nam_June_Paik-John_Cage-and-Joseph_Beuys.pdf": "ë…¼ë¬¸/ì—ì„¸ì´(ë°±ë‚¨ì¤€-ì¼€ì´ì§€-ë³´ì´ìŠ¤ ê´€ê³„/í•´ì„ ì¤‘ì‹¬)",
    "[ë°±ë‚¨ì¤€ ì‘í’ˆ 13ì„ ] ì†Œì¥ì²˜ ì •ë¦¬ (2).xlsx": "ë°±ë‚¨ì¤€ ì‘í’ˆ 13ì„  ì‘í’ˆë³„(ì‹œíŠ¸ë³„) ë²„ì „ í˜„í™©/ì†Œì¥ì²˜/ê´€ë ¨ ì •ë³´ ì •ë¦¬",
    "ë°±ë‚¨ì¤€ í•´ì™¸ì†Œì¥ í˜„í™© ì—…ë°ì´íŠ¸_2026ver.xlsx": "ë°±ë‚¨ì¤€ í•´ì™¸ ì†Œì¥ í˜„í™© ì—…ë°ì´íŠ¸(2026ver) - ì†Œì¥ì²˜/ì‘í’ˆ ì •ë³´(ì²« ì‹œíŠ¸ë§Œ ì‚¬ìš©)",
    "ë°±ë‚¨ì¤€ ë§ì—ì„œ í¬ë¦¬ìŠ¤í†  (OCR PDF)": "ë°±ë‚¨ì¤€ ì¼ìƒ ì¼í™”ë“¤ ì†Œê°œ, ìƒì „ ë°±ë‚¨ì¤€ì˜ ë§ ìˆ˜ë¡ (í˜ì´ì§€ ê¸°ë°˜ í…ìŠ¤íŠ¸, ì¸ìš©/ë°œì–¸/ì—ì„¸ì´ ìˆ˜ë¡)"

}

DEFAULT_SOURCES = [
    "ë°±ë‚¨ì¤€ ì—°ëŒ€ê¸°_ë°±ë‚¨ì¤€ë¬¸í™”ì˜ˆìˆ ì¬ë‹¨.xlsx",
    "ë°±ë‚¨ì¤€ í•´ì™¸ê¸°ì‚¬_NER,POS.xlsx",
    "The_Worlds_of_Nam_June_Paik_2000.pdf",
    "ë°±ë‚¨ì¤€ ë§ì—ì„œ í¬ë¦¬ìŠ¤í†  (OCR PDF)", 
]

# âœ… ë¼ìš°í„°ì—ê²Œ "íŒŒì¼ëª… + í•œì¤„ì„¤ëª…" ì¹´íƒˆë¡œê·¸ë¥¼ ë³´ì—¬ì¤Œ
# í˜•ì‹ ì˜ˆ:
# - íŒŒì¼ëª… :: ì„¤ëª…
CATALOG_TEXT = "\n".join([
    f"- {s} :: {SOURCE_DESCRIPTIONS.get(s, 'ì„¤ëª… ì—†ìŒ')}"
    for s in ALL_SOURCES
])


# Fixed settings (ìŠ¬ë¼ì´ë” ì œê±° + ê°’ ê³ ì •)
# =========================
vs_dir = os.getenv("PAIK_VS_DIR", "data/paik_vs")

TOP_N_EVIDENCE = 8        # ê·¼ê±° ê°œìˆ˜ ê³ ì •
SCORE_THRESHOLD = 0.22    # ê·¼ê±° ì¶©ë¶„ì„± ì„ê³„ê°’ ê³ ì •


# =========================
# Load VS (cached)
# =========================
try:
    vs = get_vs(vs_dir)
except Exception as e:
    st.error(f"VectorStore ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()


# =========================
# Session State: messages
# =========================
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ë°±ë‚¨ì¤€ ì±—ë´‡ì…ë‹ˆë‹¤.\n\në°±ë‚¨ì¤€ì˜ ì‘ì—…ê³¼ ìƒê°ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}
    ]

# =========================
# Render chat history
# =========================
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])


# =========================
# Chat input
# =========================
user_q = st.chat_input("ë°±ë‚¨ì¤€ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”â€¦")

if user_q:
    # show user message
    st.session_state.messages.append({"role": "user", "content": user_q})
    with st.chat_message("user"):
        st.markdown(user_q)

    # âœ… ìµœê·¼ 5í„´(=user+assistant 10ê°œ ë©”ì‹œì§€)ë§Œ historyë¡œ ì „ë‹¬
    recent_history = [m for m in st.session_state.messages if m["role"] in ("user", "assistant")]
    recent_history = recent_history[-10:]  # 5í„´ = ìµœëŒ€ 10ê°œ ë©”ì‹œì§€

    # generate answer (streaming)
    with st.chat_message("assistant"):
        # 1) retrieval ë¨¼ì € (ì´ê±´ ìŠ¤íŠ¸ë¦¬ë° ì•„ë‹˜)
        with st.spinner("ê²€ìƒ‰ ì¤‘â€¦"):
            out = rag_qa(
                vs=vs,
                question=user_q,
                catalog_text=CATALOG_TEXT,
                all_sources=ALL_SOURCES,
                default_sources=DEFAULT_SOURCES,
                history=recent_history,          # âœ… (í˜„ì¬ëŠ” ì„ íƒ, ê·¸ë˜ë„ ë„˜ê²¨ë‘ )
                use_rerank= True,
                top_n_evidence=TOP_N_EVIDENCE,
                score_threshold=SCORE_THRESHOLD,
            )

        # 2) ì´ì œ LLM ë‹µë³€ì„ streamingìœ¼ë¡œ ìƒì„±
        placeholder = st.empty()
        full_text = ""

        for token in rag_core.answer_stream(
            question=user_q,
            evidence=out["evidence_chunks"],
            mode=out["mode"],
            history=recent_history,             # âœ… ë©€í‹°í„´ í•µì‹¬: ì—¬ê¸°ë¡œ ì „ë‹¬
        ):
            full_text += token
            placeholder.markdown(full_text + "â–Œ")

        # 3) ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„: ë‹µë³€ì—ëŠ” ì¶œì²˜ë¥¼ ë¶™ì´ì§€ ì•ŠìŒ(ìƒì„¸ë³´ê¸°ì—ì„œë§Œ ë…¸ì¶œ)
        final_text = full_text.strip()
        placeholder.markdown(final_text)


        # expandable debug info
        with st.expander("ğŸ” ê²€ìƒ‰/ë¼ìš°íŒ… ìƒì„¸ ë³´ê¸°"):
            st.write("mode:", out.get("mode"))
            st.write("top_score:", out.get("top_score"))
            st.json(out["route"])
            st.write("evidence:")
            for i, ev in enumerate(out["evidence"], 1):
                st.markdown(f"**[{i}] {ev['cite']}**")
                st.write(ev["text"])
            st.divider()
            st.write("ì¶œì²˜:")
            if out.get("mode") == "grounded" and out.get("cite_lines"):
                for line in out["cite_lines"]:
                    st.markdown(f"- {line}")
            else:
                st.markdown("- (í˜„ì¬ RAG ë°ì´í„°ì—ì„œ ì§ì ‘ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤)")


    # store assistant message
    st.session_state.messages.append({"role": "assistant", "content": final_text})

